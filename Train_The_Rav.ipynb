{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable tensorflow warning messages.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the entire Mishnah, in Hebrew and English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "mishnah_path = r'/Users/lee/Judaism/Sefaria_Contest/sefaria_txt/Mishnah/'\n",
    "\n",
    "directories = [x[0] for x in os.walk(mishnah_path)]\n",
    "english = [i for i in directories if 'English' in i and not 'Commentary' in i] \n",
    "hebrew = [i for i in directories if 'Hebrew' in i and not 'Commentary' in i] \n",
    "\n",
    "mishnah_english = ''\n",
    "mishnah_hebrew = ''\n",
    "\n",
    "for direct in english:\n",
    "    mishnah = open(direct + '/clean.txt', 'rb').read().decode(encoding='utf-8')\n",
    "    mishnah_english += mishnah\n",
    "    \n",
    "for direct in hebrew:\n",
    "    mishnah = open(direct + '/clean.txt', 'rb').read().decode(encoding='utf-8')\n",
    "    mishnah_hebrew += mishnah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Mishnah: 1648170 characters\n"
     ]
    }
   ],
   "source": [
    "print('Length of Mishnah: {} characters'.format(len(mishnah_hebrew)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 unique Hebrew characters\n",
      "92 unique English characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(mishnah_hebrew))\n",
    "print ('{} unique Hebrew characters'.format(len(vocab)))\n",
    "\n",
    "english_vocab = sorted(set(mishnah_english))\n",
    "print ('{} unique English characters'.format(len(english_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '\"', \"'\", '(', ')', ',', '.', ':', ';', '<', '>', 'b', 'r', 'ְ', 'ֱ', 'ֲ', 'ֳ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ׁ', 'ׂ', 'א', 'ב', 'ג', 'ד', 'ה', 'ו', 'ז', 'ח', 'ט', 'י', 'ך', 'כ', 'ל', 'ם', 'מ', 'ן', 'נ', 'ס', 'ע', 'ף', 'פ', 'ץ', 'צ', 'ק', 'ר', 'ש', 'ת', '׳', '״']\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '\"', \"'\", '(', ')', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '}', '¼', '¾', '–', '‘', '’', '“', '”', '…', '\\uf0b7']\n"
     ]
    }
   ],
   "source": [
    "print(english_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove vowels from the Mishnah?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = ['ְ', 'ֱ', 'ֲ', 'ִ', 'ֵ', 'ֶ', 'ַ', 'ָ', 'ֹ', 'ֻ', 'ּ', 'ׁ', 'ׂ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the text, and create mapping dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in mishnah_hebrew])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '\"': 2,\n",
       " \"'\": 3,\n",
       " '(': 4,\n",
       " ')': 5,\n",
       " ',': 6,\n",
       " '.': 7,\n",
       " ':': 8,\n",
       " ';': 9,\n",
       " '<': 10,\n",
       " '>': 11,\n",
       " 'b': 12,\n",
       " 'r': 13,\n",
       " 'ְ': 14,\n",
       " 'ֱ': 15,\n",
       " 'ֲ': 16,\n",
       " 'ֳ': 17,\n",
       " 'ִ': 18,\n",
       " 'ֵ': 19,\n",
       " 'ֶ': 20,\n",
       " 'ַ': 21,\n",
       " 'ָ': 22,\n",
       " 'ֹ': 23,\n",
       " 'ֻ': 24,\n",
       " 'ּ': 25,\n",
       " 'ׁ': 26,\n",
       " 'ׂ': 27,\n",
       " 'א': 28,\n",
       " 'ב': 29,\n",
       " 'ג': 30,\n",
       " 'ד': 31,\n",
       " 'ה': 32,\n",
       " 'ו': 33,\n",
       " 'ז': 34,\n",
       " 'ח': 35,\n",
       " 'ט': 36,\n",
       " 'י': 37,\n",
       " 'ך': 38,\n",
       " 'כ': 39,\n",
       " 'ל': 40,\n",
       " 'ם': 41,\n",
       " 'מ': 42,\n",
       " 'ן': 43,\n",
       " 'נ': 44,\n",
       " 'ס': 45,\n",
       " 'ע': 46,\n",
       " 'ף': 47,\n",
       " 'פ': 48,\n",
       " 'ץ': 49,\n",
       " 'צ': 50,\n",
       " 'ק': 51,\n",
       " 'ר': 52,\n",
       " 'ש': 53,\n",
       " 'ת': 54,\n",
       " '׳': 55,\n",
       " '״': 56}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove vowels from the Mishnah?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = np.arange(8, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the text up into training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ה\n",
      "ַ\n",
      "ח\n",
      "ִ\n",
      "ט\n"
     ]
    }
   ],
   "source": [
    "seq_length = 200\n",
    "examples_per_epoch = len(mishnah_hebrew)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (201,), types: tf.int64>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'הַחִטִּים וְהַזּוּנִין אֵינָן כִּלְאַיִם זֶה בָזֶה. הַשְּׂעֹרִים וְשִׁבֹּלֶת שׁוּעָל, הַכֻּסְּמִין וְהַשִּׁיפוֹן, הַפּוֹל וְהַסַּפִּיר, הַפֻּרְקְדָן וְהַטֹּפֵחַ, וּפוֹל הַלָּבָן וְהַשְּׁעוּעִים, אֵינָם'\n",
      "' כִּלְאַיִם זֶה בָזֶה: \\nהַקִּשּׁוּת וְהַמְּלָפְפוֹן, אֵינָם כִּלְאַיִם זֶה בָזֶה. רַבִּי יְהוּדָה אוֹמֵר, כִּלְאָיִם. חֲזֶרֶת וַחֲזֶרֶת גַּלִּים, עֻלְשִׁין וְעֻלְשֵׁי שָׂדֶה, כְּרֵשִׁים וּכְרֵשֵׁי שָׂד'\n",
      "'ֶה, כֻּסְבָּר וְכֻסְבַּר שָׂדֶה, חַרְדָּל וְחַרְדָּל מִצְרִי, וּדְלַעַת הַמִּצְרִי וְהָרְמוּצָה, וּפוֹל מִצְרִי וְהֶחָרוּב, אֵינָם כִּלְאַיִם זֶה בָזֶה: \\nהַלֶּפֶת וְהַנָּפוּץ, וְהַכְּרוּב וְהַתְּרוֹבְת'\n",
      "'וֹר, הַתְּרָדִים וְהַלְּעוּנִים, אֵינָם כִּלְאַיִם זֶה בָזֶה. הוֹסִיף רַבִּי עֲקִיבָא, הַשּׁוּם וְהַשּׁוּמָנִית, הַבָּצָל וְהַבְּצַלְצוּל, וְהַתֻּרְמוֹס וְהַפְּלַסְלוֹס, אֵינָן כִּלְאַיִם זֶה בָזֶה: \\nו'\n",
      "'ּבָאִילָן, הָאֲגָסִים וְהַקְּרֻסְתּוּמֵלִין, וְהַפְּרִישִׁים וְהָעֻזְרָדִים, אֵינָם כִּלְאַיִם זֶה בָזֶה. הַתַּפּוּחַ וְהַחַזְרָד, הַפַּרְסְקִים וְהַשְּׁקֵדִין, וְהַשִּׁזָּפִין וְהָרִימִין, אַף עַל פִּ'\n"
     ]
    }
   ],
   "source": [
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function to map from input text to target text (just the input text shifted to the right by one character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  'הַחִטִּים וְהַזּוּנִין אֵינָן כִּלְאַיִם זֶה בָזֶה. הַשְּׂעֹרִים וְשִׁבֹּלֶת שׁוּעָל, הַכֻּסְּמִין וְהַשִּׁיפוֹן, הַפּוֹל וְהַסַּפִּיר, הַפֻּרְקְדָן וְהַטֹּפֵחַ, וּפוֹל הַלָּבָן וְהַשְּׁעוּעִים, אֵינָ'\n",
      "Target data: 'ַחִטִּים וְהַזּוּנִין אֵינָן כִּלְאַיִם זֶה בָזֶה. הַשְּׂעֹרִים וְשִׁבֹּלֶת שׁוּעָל, הַכֻּסְּמִין וְהַשִּׁיפוֹן, הַפּוֹל וְהַסַּפִּיר, הַפֻּרְקְדָן וְהַטֹּפֵחַ, וּפוֹל הַלָּבָן וְהַשְּׁעוּעִים, אֵינָם'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 32 ('ה')\n",
      "  expected output: 21 ('ַ')\n",
      "Step    1\n",
      "  input: 21 ('ַ')\n",
      "  expected output: 35 ('ח')\n",
      "Step    2\n",
      "  input: 35 ('ח')\n",
      "  expected output: 18 ('ִ')\n",
      "Step    3\n",
      "  input: 18 ('ִ')\n",
      "  expected output: 36 ('ט')\n",
      "Step    4\n",
      "  input: 36 ('ט')\n",
      "  expected output: 25 ('ּ')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 200), (64, 200)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 50000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                 batch_input_shape=[batch_size, None]),\n",
    "                                 tf.keras.layers.GRU(rnn_units,\n",
    "                                                     return_sequences=True,\n",
    "                                                     stateful=True,\n",
    "                                                     recurrent_initializer='glorot_uniform'),\n",
    "                                 tf.keras.layers.Dense(vocab_size)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size = len(vocab),\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (64, None, 256)           14592     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (64, None, 57)            58425     \n",
      "=================================================================\n",
      "Total params: 4,011,321\n",
      "Trainable params: 4,011,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict characters with untrained RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 200, 57) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  8,  7, 47, 42, 16, 15,  2, 11, 46, 17, 23, 31,  3, 23, 14,  5,\n",
       "       31, 30, 22, 21, 27, 36, 11, 37, 42,  9,  2, 19,  4, 24, 44,  1,  5,\n",
       "       31, 41,  3, 12, 41, 38, 21, 34, 30, 38, 39, 11, 30, 26,  3, 24, 11,\n",
       "        1, 43, 11,  7,  0, 46, 19, 10, 15, 34,  4, 23,  2, 34, 47, 32,  4,\n",
       "       37, 11, 21,  7, 10,  9, 13, 36, 47, 17, 37, 15, 46, 43, 23, 15, 41,\n",
       "       10, 11, 41, 26, 31, 11, 16,  0, 30, 15, 45, 18, 36,  2, 24,  4, 41,\n",
       "       36, 13,  5, 25, 28, 44,  2, 14, 29, 32, 10, 27,  4, 34, 36, 35, 21,\n",
       "       34, 14, 36, 46,  4, 25, 13, 19, 17, 47, 30, 22, 43, 16, 10, 17,  7,\n",
       "       31, 40, 29, 13, 15,  6,  9, 41, 32, 27, 29,  9, 10, 28,  7, 17, 10,\n",
       "        4, 44, 36,  3, 45, 10, 22,  5,  1, 35,  4, 14, 34, 45,  6, 14, 14,\n",
       "        0, 36,  1,  3, 47, 39, 18, 37, 27,  9, 34, 37, 29, 26,  5, 16, 19,\n",
       "        3, 18, 39, 31, 36, 34,  4, 30, 38, 34, 25, 14,  9, 40,  8, 41, 14,\n",
       "        4, 40, 40, 46, 12, 40, 14, 43, 37, 34, 41, 40, 11, 10,  1, 32, 20,\n",
       "       15, 44,  8, 46, 30, 30, 34, 22, 19, 21, 37, 11, 33,  0, 26, 21, 46,\n",
       "       47, 24, 16, 41, 36, 45, 33,  4, 38, 35, 33, 39, 41,  6, 38,  7, 22,\n",
       "       40, 12, 27,  9, 40, 16, 24, 33, 40, 20,  1, 32, 32,  0, 38, 43, 21,\n",
       "       13, 25, 17, 17, 13, 17, 11, 39,  9, 26, 27, 11, 16, 22, 13, 20, 44,\n",
       "        3, 28, 16, 39, 38, 30, 10, 47, 17, 12, 16,  0, 27, 10,  4, 36, 25,\n",
       "       23, 43, 15, 44, 35, 45,  7, 14,  0, 22,  9, 17, 38,  7, 12,  7, 28,\n",
       "        4, 19, 32, 42, 10, 33, 17,  1, 44, 13, 37,  8, 43, 21, 32, 35, 13,\n",
       "       22, 26, 26, 41, 43, 28, 35, 16,  6, 23, 15, 37, 28, 29,  1, 40,  8,\n",
       "       47, 22, 46, 11,  9, 27, 44, 22, 23, 16, 21, 12, 11, 20,  6, 15, 38,\n",
       "       43, 38, 17, 27, 17, 40, 36,  1,  8, 26, 24, 32, 12, 43, 19, 46, 23,\n",
       "        2,  7, 14, 41,  0, 31, 24, 23, 22])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'ם לַעֲמֹד בְּשָׁלֹשׁ שָׁעוֹת. הַקּוֹרֵא מִכָּאן וְאֵילָךְ לֹא הִפְסִיד, כְּאָדָם הַקּוֹרֵא בַתּוֹרָה: \\nבֵּית שַׁמַּאי אוֹמְרִים, בָּעֶרֶב כָּל אָדָם יַטּוּ וְיִקְרְאוּ, וּבַבֹּקֶר יַעַמְדוּ, שֶׁנֶּאֱמ'\n",
      "\n",
      "Predictions: \n",
      " \"ֻזְֱִׂ\\nרם'ְֲ\\nט:דֻׂאחוו.חנ:'שזתלת,ֵמ,(חֹונףיָ(םהּׂ(םעןך(ס'שָאףךכ\\nֱפׁ\\nֶׁ.צרע'מַּׁאצטיכץעת,,ד.ַָ.ֲֲט)ְלַש ףְ.ְש,לְצָ..ָ ְםמףךאַבהמנכ(ֲטרֻץגכִ,ֻףֱז)ץצלֵ:ׁמץ.טְֵ,ף:ׁ\\n\\nֱזפה'זרּף.ָקאל.ב דקט:טשלּלמֲָ,נג:ֹץחוג\"\n"
     ]
    }
   ],
   "source": [
    "print('Input: \\n', repr(''.join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print('Predictions: \\n', repr(''.join(idx2char[sampled_indices])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 200, 57)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.04316\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "EPOCHS=30 #30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "128/128 [==============================] - 270s 2s/step - loss: 2.0233\n",
      "Epoch 2/30\n",
      "128/128 [==============================] - 265s 2s/step - loss: 1.5842\n",
      "Epoch 3/30\n",
      "128/128 [==============================] - 271s 2s/step - loss: 1.3604\n",
      "Epoch 4/30\n",
      "128/128 [==============================] - 271s 2s/step - loss: 1.2386\n",
      "Epoch 5/30\n",
      "128/128 [==============================] - 270s 2s/step - loss: 1.1599\n",
      "Epoch 6/30\n",
      "128/128 [==============================] - 271s 2s/step - loss: 1.1023\n",
      "Epoch 7/30\n",
      "128/128 [==============================] - 270s 2s/step - loss: 1.0558\n",
      "Epoch 8/30\n",
      "128/128 [==============================] - 276s 2s/step - loss: 1.0179\n",
      "Epoch 9/30\n",
      "128/128 [==============================] - 290s 2s/step - loss: 0.9837\n",
      "Epoch 10/30\n",
      "128/128 [==============================] - 293s 2s/step - loss: 0.9530\n",
      "Epoch 11/30\n",
      "128/128 [==============================] - 293s 2s/step - loss: 0.9238\n",
      "Epoch 12/30\n",
      "128/128 [==============================] - 297s 2s/step - loss: 0.8947\n",
      "Epoch 13/30\n",
      "128/128 [==============================] - 285s 2s/step - loss: 0.8675\n",
      "Epoch 14/30\n",
      "128/128 [==============================] - 273s 2s/step - loss: 0.8406\n",
      "Epoch 15/30\n",
      "128/128 [==============================] - 270s 2s/step - loss: 0.8146\n",
      "Epoch 16/30\n",
      "128/128 [==============================] - 273s 2s/step - loss: 0.7875\n",
      "Epoch 17/30\n",
      "128/128 [==============================] - 268s 2s/step - loss: 0.7623\n",
      "Epoch 18/30\n",
      "128/128 [==============================] - 272s 2s/step - loss: 0.7351\n",
      "Epoch 19/30\n",
      "128/128 [==============================] - 282s 2s/step - loss: 0.7098\n",
      "Epoch 20/30\n",
      "128/128 [==============================] - 268s 2s/step - loss: 0.6850\n",
      "Epoch 21/30\n",
      "128/128 [==============================] - 268s 2s/step - loss: 0.6613\n",
      "Epoch 22/30\n",
      "128/128 [==============================] - 269s 2s/step - loss: 0.6377\n",
      "Epoch 23/30\n",
      "128/128 [==============================] - 269s 2s/step - loss: 0.6167\n",
      "Epoch 24/30\n",
      "128/128 [==============================] - 278s 2s/step - loss: 0.5960\n",
      "Epoch 25/30\n",
      "128/128 [==============================] - 287s 2s/step - loss: 0.5773\n",
      "Epoch 26/30\n",
      "128/128 [==============================] - 288s 2s/step - loss: 0.5615\n",
      "Epoch 27/30\n",
      "128/128 [==============================] - 300s 2s/step - loss: 0.5465\n",
      "Epoch 28/30\n",
      "128/128 [==============================] - 293s 2s/step - loss: 0.5329\n",
      "Epoch 29/30\n",
      "128/128 [==============================] - 299s 2s/step - loss: 0.5201\n",
      "Epoch 30/30\n",
      "128/128 [==============================] - 299s 2s/step - loss: 0.5100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, num_generate=2000, temperature=1.0):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "    \n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in np.arange(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        # remove the batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # We pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return start_string + ''.join(text_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "fmodel = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "fmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "fmodel.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מֵר אֶת הַצֶּמֶר, פִּגּוּל, וְחַיָּבִין עָלָיו כָּרֵת. לֶאֱכֹל כַּחֲצִי זַיִת, כָּשֵׁר, שֶׁאֵין אֲכִילָה וְהַקְטָרָה מִצְטָרְפִין: \n",
      "הָאַחִין שֶׁחָל עוֹלָה קוֹדְמִין לְאָדָם, כְּדֵי שֶׁיָּבֹא אֵלִיָּהוּ. בְּנֵי הַיָּבָם וְעַל הַקֹּדֶשׁ, וּמַתְחִיל, מִשָּׂרֵם מִמֶּנָּה גָּלְבּוֹן, קוֹרִין אֶת שְׁיָרֵי הַדָּשֶׁן קַלְקָחַת עָלֶיהָ: \n",
      "אֵלּוּ טֹא בְעוֹלוֹת, וּבָהֲרוּסוֹ. וְהַמְחֻבָּרִין בַּקַּרְק עַל יְדֵי עַצְמוֹ, אֵינוֹ חַיָּב אֶלָּא אַחַת. שְׁבוּעַת הַפַּת, וּפָתוּחַ לִרְשׁוּת הָרַבִּים, עַד שֶׁתִּכָּנֵס לַחֲבֵרוֹ, הֲרֵי הַשֵּׁנִי לִתֵּן לָהּ כְּתֻבָּתָהּ שִׁבְעָה זִכְרֵי כֹהֲנִים וְהַגַּיְדְּנִין עָלֶיהָ פְּרוֹזְבּוּל, רוֹעֶה הַבָּנִים אֲחֻזָּה לִשְׂדֵהָה שְׁבִיעִית מֵעֲבֵרוֹ וְאֵין לוֹ חֲזָקָה, וְיֵשׁ אוֹמְרִים, עַל הַחַר הַנָּחָשׁ, מִיתָתָן זֶל מִזַּב תְּרוּמָה, וּמַת בַּמַּעֲשֵׂר, אֵינָהּ כְּבָת. אָמַר לוֹ רַבִּי יְהוּדָה. וְרַבִּי שִׁמְעוֹן מְטַהֵר, וַחֲכָמִים מְטַהֲרִין. הַצִּיד אָנִי. אָמְרוּ לוֹ, אִישִׁי כֹהֵן גָּדוֹל, רַבִּי יְהוּדָה אוֹמֵר, אַף בַּנּוֹדֵר, הֲרֵי הוּא מְטַמֵּא בְגָדִים, הַשֶּׁרֶץ בַּתַּנּוּר, הֻכְשַׁר לֵילֵי פְסָחִים, בֵּין שְׁנִיָּה לַזָּבִים וְזֶה נוֹתֵן לָזֶה וְלֹא קָנִים לַעֲמִידָה אוֹסְרִין. שְׁנַיִם שֶׁלֹּא נֶעֱקָן. קֻפּוֹת שֶׁל חֲמִשִּׁים זוּז בִּידֵי אָדָם וְחַיָּב בַּמַּתָּנוֹת. מִתְעָרֵב בִירוּשָׁלַיִם, וְחַיְמָהּ חַטָּאת. וְהַבַּהֶרֶת וְהִנִּיחַ מַה שֶּׁאֵין כֻּלָּם מֻתָּר. אֵין תּוֹרְמִין. וּמְיֻשָּׁן, מִטַּמְּאָה בְמַגָּע וּבְמַשָּׂא: \n",
      "שִׁבְעָה בָא לִשְׁמוֹ, אָסוּר עַד שֶׁיַּגִּיעַ: \n",
      "כֵּיצַד מַעֲבִירִים עָלָיו אֶת הַתְּרוּמָה, וּמֻתָּר בִּבְגָדָיִצְבָּהּ, הַצְּדָדִין שֶׁל עֶרֶב שַׁבָּתְנוֹ וֶחָצֵר, אַף מִתְכַּוֵּן וּבֵין שֶׁאֵינָן מַחֲמִיקִים. אָמַר לוֹ רַבִּי יְהוֹשֻׁעַ, דָּגָן אָח, וְאֶת שֶׁל קַע, שֶׁנֶּאֱמַר (שם יז), עָמִיר גְּדוֹלָה וּקְטַנָּה, בִּכְפִיָּה, שֶׁהוּא כְבַשֵּׁל עִמָּהּ אֵין כָּאן לַכֹּהֵן כְּלוּם:  \n",
      "כָּל הַנִּפְרָרִים מִשִּׁפְחָה וְכָּה מִצְרִית אָשָׁם, שׂוֹרְפִין אֶת הַתְּרוּמָה וְהֶחֱזִירָהּ, מֻתֶּרֶת לְנָתִין וּלְמַמְזֵר. אֹ, לֹא בָא לִכְלָל הָקֵם, מָהַלְווּתִים מֵאַחֲרָיו: \n",
      "תַּנּוּר שֶׁנִּקְּבָה וְאַחַת קְטַנָּה\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'מֵ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "אֵין קִנֵּי זוֹבוֹתֶבֶת בַּחוּץ, אֵינָן מִצְטָרְפִין. וּשְׁאָר כָּל הַדָּבָר, חוּץ מִן הַבְּכוֹר וְהַמַּעֲשֵׂר שֶׁנֶּעֱקָב. עָשׂוּ אֲבוֹתֵיהֶן עַל מַיִם וְלֹא מִצָּה דָמָה שֶׁעָלָיו לַחִי וְכָּהוּב: \n",
      "הָיוּ שְׁנַיִם, נְטוּלָה. אִם נִמְצְאוּ דִבְרֵיהֶן קְצֹרוֹת, פְּטוּרִין, מִפְּנֵי שֶׁאֵין דַּחַת יְקִימָהּ לְחוֹמָה, עַד שֶׁיַּעֲמִן דַּם הַפָּר, וְהַמַּרְחֶשֶׁת, וְהַחַלּוֹת, וְהָרַג בֶּן חֲנַנְיָן וּמוֹצְאוֹת בְּכֶסֶף מַעֲשֵׂר, וּפוֹסֵל אֶת הַמִּקְוֶה. נְקוּבַת הָאַלְמָנָה, וְנֶאֱכֶלֶת בְּיַד אֶחָד, וַחֲכָמִים אוֹמְרִים, אִם שִׁיֵּר קֹרָאַחַר שֶׁעֲשָׂאָהּ לְשֵׁם קַבָּלִין, שִׁעוּרוֹ בְרֹאשׁ הָאִילָנוֹת, טָהוֹר מִן הַמָּחוֹם, וְעַל הַדְּרָכִים, וְעַל הַדְּלָתוֹת, וְאֵינוֹ נֶאֱכָלוֹת אֶלָּא אַתָּה סֹגֶת. אֵיזֶהוּ עָרִיס, טַמִּין וְחֶצְיָן לְמַרְחִיקִין וְנִמְלְכוְ וְאֵינוֹ בְכוֹר לַנַּחֲלָה וְלֹא בְמֶלַח וְלֹא מְקַיֵּם, וְאֵינוֹ שָׁוֶה אֶלָּא בִשְׁבוּעָה. כְּדֵי גְמִי יָמִים לִכְלִי קִשּׁוּת אֶחָת. מַעְשַׂר עָנִי שֶׁיָבֹא לָצֵאת בְּכַבֵּיצָה, שֶׁבֵּינוֹ לְבַשֵּׁל בְּחָל עִם כְּרֹנָה. בַּעֲשָׂרָה עָלָיו, וּמָאתַיִם, וְאֵין אָד, עַד שֶׁיֻּדַּן ה' הַמַּעֲלָה אוֹכֶלֶת בְּתוֹךְ בֵּיתוֹ לְקַיְּמָהּ וּמִצָּה הָרִאשׁוֹנָה שֵׁנִי. לִמְחֻבָּר לַשֵּׁם אֶת עוֹר, מֵי שְׁלשָׁה יָמִים, קִנְיָן. וְאִם לָאו, הֲרֵי הֵן כְּאַחַת, וּמוֹכֵר אֶת הַבְּרֵכָה, הַצָּף מִדַּת כַּאֲנָשִׁים שֶׁלֹּא בִכְּרוּ וְתָבְעָהּ מִן הַחֲלָבָיו. וְשֶׁהָיָה מִתְכַּוֵּן לִהְיוֹת מַנִּיחִין אוֹתוֹ, וְנוֹלֵף לָהּ מִטַּמֵּא לַמֵּתִים. לֹא יִמְכְּרוּ אֶלָּא חֲמִשִּׁים זוּז, אֵין יָכוֹל לְחֻלִּין, אַף כָּל דָּבָר שֶׁהוּא מִשּׁוּם שְׁנֵי קְבִירָה עוֹשִׂים תְּמוּרָה. עָרְלָה כְתֻבָּתָהּ. הָיְתָה שְׁנִיָּה, שֶׁהָיָה שְׁתֵּי כְתֻבּוֹת אֵינָהּ לְבֵין אַחִיב: \n",
      "גְּרוּשָׁה וַחֲלוּצָה, אֶחָד גְּרוּשָׁיו וְאֶחָד קָדָשִׁים שֶׁחַיָּב בְּכֻלָּן. וַחֲכָמִים אוֹמְרִים, כֹּל שֶׁיֵּשׁ בּוֹ יְדִיעָה לַאֲכָלוֹ, אֵינוֹ מוּפָר. אָמַר רַבִּי יוֹסֵי, מַה הִיצִיא הַבַּיִת מָעָרְלָה. כְּשֵׁרִין וְהַחִיצוֹנָה מְהַלֶּכֶת וְיַקְרִיבוּ אֶת אֲחִי אִמָּא בְאוֹתוֹ וְאֶת בְּנֵי מוֹנִים: \n",
      "זֶה הַכְּלָל, מְחֻסַּר זֶה לְעַבְדֵיהֶן וְחַטָּאוֹת הַחֹמֶץ וְחָ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'אֵ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בְּיָדָהּ וֹלַד שֶׁל יַיִן, אֵין לוֹ טוֹעֵם, כָּל הָרָעוּת אֵין לוֹקֵחַ אֶת הַזָּב, אֵין לִי בִנְכָסַיִךְ וּבַקָּשָׁה וְאֵין בֵּינִי לוֹקֶה. רַבִּי עֲקִיבָא אוֹמֵר, כַּמָּה אֶת הַשַּׁבָּת הַחֲמוֹר. הַחוֹבָל לָא וּלְנוּלָה וּמְחֻלְיָלָיו עַד סוֹף הָעוֹלָם. וְהַבַּיְדִּשְׁמֹנִים וְהָאֲבָנִים וְעָמַד בְּתוֹךְ שְׁלשִׁים וְאֶחָד וּמֵאֲמָנָה. מִן הַצַּד, אֵינוֹ נוֹהֵג אֶלָּא בְאוֹמֵר וִיק, בִּזְמַן שֶׁהֵן מֻרְחוֹק שִׁמְעוֹן אוֹמֵר, הַגַּנָּבִים שֶׁהִיא עוֹשָׂה אֶת הֶחָצֵר. לֹא יִטְבֹּל בָּאֶמְצַע. הָיְתָה בַתַּנּוּר, מַחֲזִיקִים יְדֵי חוֹבָתוֹ לַנָּשִׂיא אֶלָּא לְנִדָּה. הַמַּנִּיחַ אִסָּר שֶׁמָּד לִשְׁתֵּי הַלֶּחֶם, וְלֹא מִן הַמֻּקָּף וּצְרִיכָה גֵט וַחֲלֹב אִם תִּנָּשֵׂא וְלֹא תֵעָרַךְ בַּכַּלְיָט, וְהַמּוֹל, דִּבְרֵי רַבִּי מֵאִיר. רַבִּי יְהוּדָה אוֹמֵר, מֵבִיא וְקִיְּמָהּ. אֵין שְׁנֵיהֶם אֵינָן בְּרֹחַד מִתּוֹךְ שֶׁל זְקֵנָה, יַעֲלוּ וְלֹא תִקַּח מְטַהֵר אֶת יִשְׂרָאֵל: \n",
      "בָּא לָהֶם שֶׁיָּצָא מִן הַצְּדָדִין, קֻשְׁמָר לוֹ מִן קַבִּין, וּפוֹסֵל אֶת הַתְּרוּמָה וּמַעֲשֵׂר, דִּינֵי נְפָשׁוֹת מִטַּמְּאִים בַּנְּכָסִים שֶׁבַּשָּׁמַיִם, שֶׁל פִּרְכְּמֵי, אֵינוֹ זוֹרֵק אֶת הַדָּם, אֶלָּא אִם רָצָה לַחֲבֶרְתָּהּ שֶׁלֹּא בִכְּרָה אֶחָד, שְׁנֵיהֶן חוֹזְרִין לִכְלִי אֶחָד שֶׁאֵין לוֹ מַתִּיזִין, וּבַחוּץ, חוּץ מִדְּבַשׁ, מֵאֵימָתַי מֻתָּר אָדָם לִקַּח לוּף בֵּין חַיִּין. חִלְּקָן, זֶה שֵׁם שֶׁהוּא מַחֲזִיר אֶת רַבּוֹ, וְהַמְאַחְרָה, בֵּית שַׁמַּאי אוֹמְרִים, תְּנוּפָה חַרְבָּה, מֻתָּר בְּפִיךְ הוּא, שֶׁנֶּאֱמַר (שמות כב), יְזַמֵּחַ. אַרְבָּעָה נְקוּבָה לְמַחֲצַת לְשָׁם, וְחֶצְיָן לְמַטָּן וְלַח. וְלֹא דָנוּ בָאֶמְצַע: \n",
      "אַחַת בֵּין הָעַרְבַּיִם, וְתֵאֵין הַזַּיָּרִים, יַעֲלוֹ בֶּן חָרָשׁ, הַשּׁוֹלֵךְ לַגָּת. גֵּט לָזוֹ וְשִׁלְּחָהּ לַעֲבֵרָה, פָּטוּר מִלְּשַׁלֵּם. נָתְנָה לָהּ גֵּט לְאִשְׁתִּי ה' אֱלֹהֵיהֶם עִמָּה. בַּעֲשָׂרָה, מְקוֹם שֶׁהָיָה שִׁכְחָה, יְדַיֵּם בְּדִינֵי מָמוֹנוֹת, בִּשְׁלֹשָׁה. מוֹתְרָן סֻפְגְּדָה עָלָיו וּטְפָחַיִם וּמֶחֱצָה לְמֶחֱצָה. אָמַר רַבִּי יְהוּדָה, אֵימָתַי, בִּזְמַן שֶׁהוּא בִירוּשָׁלַיִם, דִּבְרֵי רַבִּי מֵאִיר. רַבִּי יְהוּדָה אוֹמֵר, מִשֶּׁל אֶחָד \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'בְּ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "עַל יְדֵי חוֹבָתוֹ. אָמַר רַבִּי אֱלִיעֶזֶר בֶּן צָלִין תַּחְתֶּיהָ, יַנִּיחֶנָּה לַחֲבֵרוֹ, עַד שֶׁיְּהֵא נִפְרָרִין וּשְׂעִירִים מַעֲשֵׂר שֵׁנִי שֶׁלָּהֶם וְיֵאָכְלוּ בֵיתָה אֵלּוּ מַצִּילִין זְרָעִים, אֵינָן חוֹשְׁשִׁים. וְאִם עֲשָׂאָן גִּדּוּלֵיהֶן, בִּשְׁלֹשָׁה. גֵּרְשָׁן הִיא הֲנָאָה, שֶׁנֶּאֱמַר (ויקרא ז), וְהִקְטִיר אֶת הַגַּנְטִילִין בִּסְקַדֵּשׁ מְשַׁלֵּם נֶזֶק שָׁלֵם, שֶׁאֵין אָדָם זֶה מְגַלֵּחַ חֲצִי נָזִיר, וְשָׂעִיר הַנִּשְׂרָפִין. רַבִּי יוֹסֵי מַתִּיר. וְכֻלָּן שֶׁעָשׂוּ מִשֶּׁרַבּוּ עַל לַחֲבֹת מִדִּבְרֵי, שׁוֹר שֶׁל תֶּלַם שֶׁל זְהוִּיתָתוֹ, הֲרֵי הוּא כְתוֹבָה וּלְסַפָּר כָּרָאוּי, מְעָרְבִין אֶחָדוֹת:  \n",
      "שְׂכָר מַחֲלָהָה אֶל הַמִּדָּה. הַחוֹבָה מְלֻפֶּה מִשְׁקָלָהּ לְיִינָה, הִיא גְדוֹלָה, שְׁחִיטָתוֹ פְסוּלָה. רַבִּי יְהוּדָה אוֹמֵר, אֲפִלּוּ כָל הַנָּשִׂיא אוֹמֵר, אִם מֵעַכִּיר. אָמַר לוֹ רַבִּי עֲקִיבָא, אֲכִילַת הַיּוֹם, מִשֶּׁיַּבְשִׁיל. בֵּית שַׁמַּאי אוֹמְרִים, יוֹצִיאוּהוּזָה אֶת יָדָיו לְמַעְלָה מִן הַצִּיץ וְכוֹסְרִין, וּמַיִם בְּמַיִם שֶׁאֵין חָכְמָה. אִם הִתְקִינָהּ לְמָה רָאִית, טָהוֹר. גִּטְּיָהּ מַתָּנָה אַחַת. לָזוֹ וְרֻבּוֹ לַמַּיִם בְּיוֹם טוֹב, בֵּית שַׁמַּאי מְטַמֵּא חֲבֵרוֹ:  \n",
      "עוֹר שֶׁסָּכָן בְּיָבֵשׁ הָיָה לִפְנֵי הַמּוֹעֵד לִתְרוּמָה, שֶׁהִיא לִפְנִים, חַרְדָּל וְהוּא שָׁם הוּא וְכִי אֶלָּא תוֹכָהּ: \n",
      "הָיָה עוֹלֶה בְכֻלָּן שֶׁחָבַל בְּאָדָם, כָּל שֶׁאֵינוֹ מִתְקָעַ בַּכֹּהֵן, כְּלֹא הַנָּזְרָה וְהַמַּדְלוֹ וּמְחֻפַּרְעֲצִי נוֹעֲלוֹת, בִּשְׁנֵי כֵלִים, וְהֵבִיא בִכּוּרִים, זוֹכֵל שְׂדֵה בֶן לוֹ וְנִתְגַּלּוּ, נִשְׁבְּרָה הַרְבֵּה. וְאֵין מַפְטִירִין בַּפָּרָה מִתָּחִיד:  \n",
      "עָמְדֶּשׁ בְּתוֹכוֹ, חַיָּב. אִם מַתְחִילִין בַּנָּשִׁים, שֶׁחוּץ לַמֶּרְחָץ, קַנְקַן הָאָרֶץ וְהוּא נוֹגֵעַ בְּכַרְפֶּרֶת. רַבִּי שִׁמְעוֹן אוֹמֵר, אֶחָד בַּצָּרוֹכוֹת, חוּץ מִבַּנְּדָלִים. בִּזְמַן שֶׁאֵין שָׁם אַרְבַּע אַמּוֹת מֵעִקַּר גְּרָנוֹת לְכָל הַחֲבֵרִים בַּקֹּדֶשׁ וְלַבְּגָדִים, וְהוּא נִמְדֶּדֶת פְּתֻוָּנוֹת וְשֶׁל מִסְפְּטוֹר לִמְקוֹם הַזּוֹלָה, וּדְחַפֵּם אוֹ אֹהֲבוֹ וְלֹא בְזוֹ, הִטִּיל בְּעַצְמוֹתוֹ. וְכֵן הַדָּמִים מַרְבֶּה בִמְלִיאֵל, בָּא לוֹ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'עַל'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "לֹכֶם מִן הַמֵּת, נוֹטֵל תְּשִׁיעֶזֶר אוֹמֵר, אֵין מְמִיחִין הֶעָרֵב. חָלְצוּ לְתוֹךְ שָׂדֶהוּ. אָכְלָהּ וְהִשְׁלִים בֵּין לַחֶבֶל, וְחָזְרָה אֶצְלָהּ. וּבֵית הִלֵּל מַתִּירִין: \n",
      "הַמַּעֲשֵׂר עָבְרוּ בֵית הִלֵּל לְבֵיתוֹ, אָבִינוּ עַל יְדֵי צָלוֹת אָבִיו, וְאֶת בְּנוֹ וּבֵית הַשְּׁלָחִין, וְהֶחָזֶרֶת וְחָפִין. הַלּוֹמֵד בַּחוּץ, וּבָהּ שְׁלֹשָׁה עַל שְׁלֹשָׁה מִלְמַעְלָן וְאֵינוֹ חַיָּב בָּהּ. אֵלּוּ הֵן מַשִּׂיאִין אֶת הָעָרְלָה, כִּי טַבַּעַת וְנַעֲשֵׂית עֲגֻלָּה, הָאוֹחֲזָיו מַרְאוֹת אוֹר אַחֲרֵיהֶם, אֶל יָחִיד, וָמֵת, לֹא עָכָה בָהֶן נָשִׁים, תֵּצֵא וְתִרְעֶה בָעֵדֶר. מִשֶּׁיַּסִּיקֶנּוּ, פְּטוּרִין. וְעַל קְטַנָּה בַת יִשְׂרָאֵל שֶׁנִּסֵּת לְיִשְׂרָאֵל, וְהִשִּׂיאוּ אַמְרֹאשׁ בִּזְמַן שֶׁהִיא לוֹקֶה אַרְבָּעִים. אֲבָל הוֹדוּ לוֹ חֲכָמִים. וְכֵן שְׁתֵּי גְרוֹנִין, אֶחָד בִּכְלִי אֶחָד, אֲפִלּוּ בְחֶזְקַת טֻמְאָה. הַחִיצוֹן מְחַלֶּה. הֻתַּר אֶחָד, כָּבוּשׁ שֶׁאֵין בָּהֶן כַּמָּה הֶדְיוֹט, הֶעֱבִירוֹ עַל גַּבֵּי שְׁלֹשָׁה, וּשְׁנֵי פַר דַּרְכִּיל, שָׂעִיר הַגִּתּוֹת טְהוֹרוֹת וְהֶחֱזִירָהּ, פְּסוּלָה, שֶׁרַגְלַיִם, לֹא דָנִין אוּחוֹ בְעוֹלֶה מִדְּמֵי שְׁבִיעִית. הַמַּסְפֵּר, קָצַר חֲצוֹצְרוֹת וּנְשָׁכוֹת, בְּקִילוֹן, רַבִּי שִׁמְעוֹן אוֹמֵר, הַטְּרֵפָה, וְיוֹצֵא דֹפֶן: \n",
      "יַסִּיקֵם מַשְׁקֶה טוֹפֵחַ מִלְּמַטָּן, טְהוֹרִין. מוֹתַר רְשׁוּת הָרַבִּים לִשְׁתֵּים עֶשְׂרֵה צְרִיכִין שֶׁבְּיִשְׂרָאֵל, אִם יֶשׁ בּוֹ בְנִי, אוֹ שֶׁאָבְדוּ חִנָּיו. וְאִם יֶשׁ לָהֶן סְתוּמַת מַעֲשֵׂר, וּפוֹסֶלֶת בַּשְּׁבִיעִית, וּבִרְחוֹבָיו כִּירָה. וְכַמָּה הִיא מִכָּאן וְאֶחָד מִן הַתַּחְתּוֹן, צוֹרֵי פְּלֵי זְכוּכִית, לְפִי שֶׁמֵּת הָאוֹמֵר לַחֲבֵרוֹ פֵּרוֹת רְאִיַּת הַנִּיחַ בַּבִּכּוּרִים, שֶׁהֵן עֻמְרְמָל מַתָּנוֹת לָמָּה נִתְכַּוֵּן לַהֲרֹג אֶת מְקוֹמוֹ: \n",
      "סָכוֹס וְהָאֲבַטִּיחַ שֶׁנִּמְצָא בַּעֲבוֹדָה זָרָה, שְׁחִיטָתוֹ מִשּׁוּם שְׁבוּת, אָסוּר. לְעוֹלָם מַה שֶּׁאֵינָהּ מְדַמַּעַת בִּזְמַן שֶׁיֶּשׁ בְּתוֹכָהּ מָדוּי, בֵּית שַׁמַּאי אוֹמְרִים, כִּמְלֹא מַלְכִּיס: \n",
      "אָשָׁם בִּכְלָל יָרָק, וְקִבְּלָן רַבִּי מֵאִיר בְּכָל הַמִּצְוָה, שֶׁהָיָה שָׁם מֵאֶמְצִיאֵי שְׁפִירוֹת. אֲבָל בְּמֻרְחֶה הָרִא\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'ל'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מְַּיָח, מַה הוּא. חַטַּאת הָעוֹף טָמֵא. הָיוּ שְׁנֵיהֶם שָׁוִין. אָמַר רַבִּי מֵאִיר, לֹא הָיִיתִי, הָעוֹלָה תִּקְרַב עוֹלָה, וְזֶה הַלּוּחַ בְּנֵי חַרְבַּיִם. בָּרִאשׁוֹנָה הָיוּ פְטוּרִין, דִּבְרֵי רַבִּי מֵאִיר. וַחֲכָמִים אוֹמְרִים, פְּעָמִים שֶׁהוּא בְחֶזְקָתָן, אֲפִלּוּ כְשֵׁרִים בְּמַשְׁקִים, מוֹחֲצִי אֶת דָּמוֹ. צָלְכֵי מָעוֹת, כְּדֵי לָמוּל בְּנַטּ, הֲרֵי זֶה יָכוֹל לַהֲסִיטָן, טְהוֹרִין. רַבִּי יְהוּדָה אוֹסֵר, הַמֵּת מְשַׁמֵּשׁ כְּנֶגֶד אֲרֻבָּה, הַבַּיִת טָמֵא. טֻמְאָה בַבַּיִת, מַה בּוֹ שֶׁל חֻלִּין, שֶׁנֶּאֱמַר (במדבר טז), וְנֶאֱכָלִים לִפְנִים מִן הַקְּלָעִים, קָרָאוּ לְאַחַר זְמָן. אָמַר רַבִּי עֲקִיבָא, אֲנִי אֲדַסֵּט בָּהּ. אָמְרוּ לוֹ אֱמֹר, אִם הָעוֹן עָשָׂר חֹדֶשׁ. מִשְׁפַּט אֶחָד, חַיָּב עַל הַשְּׁבוּעָה כִשְׁתֵּי הָאִילָן. אֲבָל עִמָּהּ טַעַם דָּבָר שֶׁדַּרְכּוֹ לְהַקְטִיר, דַּיָּהּ שְׁעָתָהּ. וְיֵשׁ אוֹכְלוֹת מַשְׁקִין יְבֵשִׁין, לְהָבִיא אֶת יְשָׁלָה שֶׁל יִשְׂרָאֵל, אָסוּר. קָדָשִׁים בִּירוּשָׁלַיִם, וְהָיוּ עֵדָיוָהָיְתָה בָאָרֶץ, וְחַלָּה נוֹהֵג בַּיָּבֵשׁ, עֵדוּלָה מוֹה, כֵּן מִקָּרְבְּנוֹתָיִם. כֵּיצַד מַעֲלִין לוֹ חֶסַּאי הָיָה מַכְנִיס, מֵנִיחַ יַעֲקֹב, וַחֲכָמִים פּוֹטְרִין. הַמַּנְהִיג נְסָכִים לֶאֱכֹל יֶשׁ בּוֹ אָמוּר וְדִבּוּרִי עֵדֶם לִכְתֹּב חֶזְקָתוֹ: \n",
      "נִפְתַּח אַחַד מֵהֶן וְלֹא שְׁנַיִם, חַיָּבִין. וּשְׁאָר כָּל הַיּוֹם כָּל שֶׁהֵן, פְּסוּלִין. חֲמִשָּׁה דְבָרִים רַבָּן גַּמְלִיאֵל גּוֹלֶה. רַבִּי יְהוּדָה אוֹמֵר, הֱוֵי מַגָּע: \n",
      "לְמַעְלָה מִזּוֹ. מֵאָה וְעֶשְׂרִים אַמָּה, לֹא יָבִיא בְמָה, הֲרֵינִי נָזִיר אִם אָמַר, הֵן הָרִאשׁוֹנִים. בָּהּ יְדִיעָה בַתְּחִלָּה, בֵּין בַּתְּחִלָּה, דִּבְרֵי רַבִּי מֵאִיר, לֹא נִבְרָא בֶן שִׁבְעָה. וְהָאֲבָנִים טְהוֹרִים, וְהַפִּלְפְּלִין, טְהוֹרִין: \n",
      "עֶשֶׂר טֻמְאוֹת פְּנוּפִין, חַיָּב, מִפְּנֵי שֶׁהֵם גִּבּוּחַ שֶׁהִיא תוֹבַעַת, וּבְמַחַט שֶׁנִּטְמָא, דִּבְרֵי רַבִּי מֵאִיר. רַבִּי יְהוּדָה, אוֹ עַל מְנָת שֶׁיֶּשׁ לִי בְיָדֶךָ, אָמַר לוֹ מֵת, וְהוּא שֶׁנִּשְׁחֲטָה שֶׁלֹּא בִכְּרָה, יִבָּטֵל. אָמַר רַבִּי יְהוּדָה, נִשְׁמַט הַבַּרְדְּמִין גְּדוֹלִים וְקִשְּׂרוּ וְהָאִישׁ כְּפוּלֵי גִדּוּשִׁין כּ\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'מַ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "מַרְדֵּה. שָׁלֹשׁ עַל שָׁלֹשׁ שֶׁנִּתְנַסְּלוּ מְלַאכְתָּן שֶׁל מְצֹרָע, וּשְׂמֹאלוֹ וְאֵין בָּהּ יְדִיעָה, לֹא יָקֹב. וּבְחָרוּב וְהֶחֱזִיקוֹ, יִשָּׁפְכוּ לְתוֹךְ הַחֹלֶב: \n",
      "רַבִּי יְהוֹשֻׁעַ אוֹמֵר, בַּשְּׁבִיעִית מִנִּכְסֵי אִסָּרוֹת, וְלֹא סִימוֹן בְּזוֹחֲלִים, שֶׁהֵן כְּשֵׁרִים. וְנֶאֱכָלִין בְּשַׁבָּת, וְחֹמֶץ הָאֲמוּרָה בַתְּחִלָּה: \n",
      "הָאוֹנָאָה, אַף עַל פִּי שֶׁחֲשֵׁכָה, וּקְדֻשַּׁת הַשֵּׁם, וּתְהִאשֵׁר מִן הַמֵּת וְעֶצֶם כַּשְּׂעֹרָה. רַבִּי יְהוּדָה אוֹמֵר, אַף מִי שֶׁהָבִיא מִפְּנֵי שֶׁהֵן בִּרְשׁוּתוֹ שֶׁל אֲחֵרִים, וְאֶחָד לַתָּא מִן הַשִּׁיפָה בִּשְׁעַת הוֹצִיא, מוֹסִיף עוּר גֵּט וְאת לַאֲחֵרִים בְּבֵית הַפְּרָע. וְהָאוֹנִינִי נוֹהֵג בַּתְּרוּמָה. רָאָה אַחַת מַעֲשֵׂה: \n",
      "אֵלּוּ אֵינָן מְעֹרְבוֹת, הַמַּיִם שֶׁבְּתוֹךְ הֶקְדֵּשׁ, הַבָּשָׂר יֵאָכֵל: \n",
      "בַּחֲמִשָּׁה עָשָׂר בּוֹנְעִין בּמֵד. אָמְרוּ לוֹ, אִם כֵּן רִפָּנֵס הָיְתָה שָׁם בֵּית דִּין, שֶׁמַּצְנִיעִין הָאֵמוּם אֶחָד, אֲבָל רֹאשׁוֹ לַמּוֹסֵף רוּחַ חֲכָמִים. הַפֶּסַח שֶׁיֶּשׁ לָהּ וַאֲנִי אֶחֱר. אָמְרוּ לוֹ, מָמוֹן הָיְתָה, וּמְצֹאָב שֶׁהוּא מַאֲכַל פְּחוּתָה: \n",
      "אֵין מַדְלִיקִין, אֵין מְחַלְּלִין כֶּסֶף וּפְרִיָּה, טָמֵא. דֶּבֶר כַּהֲנָיָה, לֹא הָיוּ מַשְׁקִין אֶת בְּנוֹ. רֹאשׁוֹ שֶׁל זֶה וְקַרְנָיו, וְקֹל עִמּוֹ וְאַחַר כָּךְ שְׁחָטָה. וְכֻלָּן שֶׁקְּבֻצָּרוֹת בֵּין לַחִין בֵּין אַף זוֶזְמָן וְלִדְמֹרַבַּעְתּוֹ וְהוּא לוֹקֶה. וְכוֹפִין אֶת הַיַּיִן וְאֵין בּוֹ כָרֵת, חוּץ מִן הַתַּבְנִין, וְהַחֶנְוָנִיּוֹת, מִשֶּׁתִּקְרַב שְׁלָמִים. הָיוּ נֶאֱמָנִין עַל מַה שֶּׁאֵין כֵּן בַּשְּׂעוּיִשְׂרָאֵל, וְשׂוֹרְפִין פֶּחָתִי וְזֶה מְקַדֵּשׁ יָדָיו וְרַגְלָיו, בְּפִיו בִּרְשׁוּת הָרַבִּים, תָּל אוֹמְרִים, הַדִּינָר קָרְבָּנוֹת: \n",
      "הַצְּדוֹקִי נֶאֱמָנוֹת. וּבֵית הִלֵּל אוֹמְרִים, כֶּרֶם הַנְּגָעִים, פְּרוּמִין מִן הַשּׁוּק שֶׁאֵינוֹ עַל מַה שֶּׁעָמָר, תִּיק מִתְוַדִּיקִם, הֲרֵי זוֹ אֲסוּרָה: \n",
      "אֵלּוּ בַעֲלֵי מוּמִין תְּמִימִים, וְנֶאֱכָלִין בְּכָל הָעִיר עֲשָׂרָה טְפָחִים, אוֹ לָשָׂה מִשֶּׁקִּלְקְלוּ הַמַּיִם, פְּסוּלִין. אִם נִמֹּחוּ. טָעַ מִתַּחַת שְׂכָרְשֶׁיהָ, תַּחְתֶּיהָ טְמֵאִין, וְנָתְנוּ לוֹ זְמַחֲרָן אֶלָּא לְת\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(fmodel, u'מַ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
